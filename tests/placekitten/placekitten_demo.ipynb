{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PlaceKitten Demo Notebook üê±\n",
    "\n",
    "Interactive demonstration of PlaceKitten's Phase 2 features:\n",
    "- Computer Vision Pipeline\n",
    "- Smart Cropping Engine\n",
    "- Step Visualization System\n",
    "- Filter Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom IPython.display import Image, display\nimport numpy as np\n\n# Add src to path\nproject_root = Path(os.getcwd()).parent.parent\nsrc_path = project_root / \"src\"\nsys.path.insert(0, str(src_path))\n\n# Create output folder for notebook images\noutput_folder = Path(\"notebook_output\")\noutput_folder.mkdir(exist_ok=True)\n\n# Import PlaceKitten\nfrom placekitten import PlaceKitten, list_available_filters\n\nprint(\"‚úÖ PlaceKitten imported successfully!\")\nprint(f\"üìÅ Project root: {project_root}\")\nprint(f\"üìÅ Source path: {src_path}\")\nprint(f\"üìÅ Output folder: {output_folder.absolute()}\")\n\n# Helper function to get output path\ndef get_output_path(filename):\n    return str(output_folder / filename)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic PlaceKitten Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize PlaceKitten\nkitten = PlaceKitten(\"demo\")\n\n# Show available images\nimages = kitten.list_available_images()\ncount = kitten.get_image_count()\n\nprint(f\"üê± Found {count} kitten images:\")\nfor i, img in enumerate(images, 1):  # Show with 1-based indexing\n    print(f\"  {i}: {img}\")\n\n# Show available filters\nfilters = list_available_filters()\nprint(f\"\\nüé® Available filters: {', '.join(filters)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Generate a basic image\nprocessor = kitten.generate(width=600, height=400, image_id=1)  # Now 1-based indexing\nbasic_output = processor.save(get_output_path(\"notebook_basic.jpg\"))\n\nprint(f\"‚úÖ Basic image generated: {basic_output}\")\n\n# Display the image\ndisplay(Image(basic_output))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Smart Cropping with Computer Vision\n",
    "\n",
    "This demonstrates the 9-step intelligent cropping process:\n",
    "1. Original analysis\n",
    "2. Grayscale conversion\n",
    "3. Noise reduction (Gaussian blur)\n",
    "4. Edge detection (Canny algorithm)\n",
    "5. Contour analysis\n",
    "6. Subject bounding box\n",
    "7. Rule of thirds grid\n",
    "8. Optimal crop area\n",
    "9. Final result"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Generate image with smart cropping and step visualization\nprocessor = kitten.generate(width=800, height=600, image_id=2)  # Start with different aspect ratio\n\n# Apply smart cropping to 16:9 format with step visualization\nsmart_processor = processor.smart_crop(\n    width=800, \n    height=450,  # 16:9 aspect ratio\n    save_steps=True,\n    output_prefix=str(output_folder / \"notebook_demo\")\n)\n\n# Save final result\nsmart_output = smart_processor.save(get_output_path(\"notebook_smart_crop.jpg\"))\nprint(f\"‚úÖ Smart cropping completed: {smart_output}\")\n\n# Display the final result\ndisplay(Image(smart_output))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Step-by-Step Visualization\n",
    "\n",
    "View each step of the computer vision pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Display all processing steps\nstep_files = [\n    (get_output_path(\"notebook_demo_1-original.jpg\"), \"1. Original Image\"),\n    (get_output_path(\"notebook_demo_2-grayscale.jpg\"), \"2. Grayscale Conversion\"),\n    (get_output_path(\"notebook_demo_3-blurred.jpg\"), \"3. Noise Reduction (Gaussian Blur)\"),\n    (get_output_path(\"notebook_demo_4-edges.jpg\"), \"4. Edge Detection (Canny)\"),\n    (get_output_path(\"notebook_demo_5-largest-contour.jpg\"), \"5. Contour Analysis\"),\n    (get_output_path(\"notebook_demo_6-bounding-box.jpg\"), \"6. Subject Bounding Box\"),\n    (get_output_path(\"notebook_demo_7-rule-of-thirds.jpg\"), \"7. Rule of Thirds Grid\"),\n    (get_output_path(\"notebook_demo_8-crop-area.jpg\"), \"8. Optimal Crop Area\"),\n    (get_output_path(\"notebook_demo_9-final.jpg\"), \"9. Final Result\")\n]\n\n# Create a grid display\nfig, axes = plt.subplots(3, 3, figsize=(15, 15))\nfig.suptitle('PlaceKitten Smart Crop - Computer Vision Pipeline', fontsize=16)\n\nfor i, (filename, title) in enumerate(step_files):\n    row = i // 3\n    col = i % 3\n    \n    if os.path.exists(filename):\n        img = mpimg.imread(filename)\n        axes[row, col].imshow(img)\n        axes[row, col].set_title(title, fontsize=10)\n        axes[row, col].axis('off')\n    else:\n        axes[row, col].text(0.5, 0.5, f'File not found:\\n{Path(filename).name}', \n                          ha='center', va='center', transform=axes[row, col].transAxes)\n        axes[row, col].set_title(title, fontsize=10)\n        axes[row, col].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n# Show which files were created\ncreated_files = [f for f, _ in step_files if os.path.exists(f)]\nprint(f\"‚úÖ Created {len(created_files)} visualization steps\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filter Pipeline Demo\n",
    "\n",
    "Test all available filters with the same source image:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test all available filters\nfilters_to_test = ['grayscale', 'sepia', 'blur', 'invert', 'pixelate']\nfilter_results = {}\n\nbase_processor = kitten.generate(width=400, height=300, image_id=3)  # Now 1-based indexing\n\n# Generate original\noriginal_file = base_processor.save(get_output_path(\"notebook_original.jpg\"))\nfilter_results['original'] = original_file\n\n# Apply each filter\nfor filter_name in filters_to_test:\n    try:\n        filtered_processor = base_processor.apply_filter(filter_name)\n        output_file = filtered_processor.save(get_output_path(f\"notebook_{filter_name}.jpg\"))\n        filter_results[filter_name] = output_file\n        print(f\"‚úÖ {filter_name} filter applied\")\n    except Exception as e:\n        print(f\"‚ùå {filter_name} filter failed: {e}\")\n        filter_results[filter_name] = None\n\nprint(f\"\\nüìä Generated {len([f for f in filter_results.values() if f])} filter variations\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display filter results in a grid\n",
    "available_filters = [(k, v) for k, v in filter_results.items() if v and os.path.exists(v)]\n",
    "n_filters = len(available_filters)\n",
    "\n",
    "if n_filters > 0:\n",
    "    cols = 3\n",
    "    rows = (n_filters + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(12, 4 * rows))\n",
    "    fig.suptitle('PlaceKitten Filter Pipeline Results', fontsize=16)\n",
    "    \n",
    "    # Handle single row case\n",
    "    if rows == 1:\n",
    "        axes = [axes] if cols == 1 else axes\n",
    "    \n",
    "    for i, (filter_name, filepath) in enumerate(available_filters):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        \n",
    "        ax = axes[row][col] if rows > 1 else axes[col]\n",
    "        \n",
    "        img = mpimg.imread(filepath)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(filter_name.title(), fontsize=12)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(n_filters, rows * cols):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        ax = axes[row][col] if rows > 1 else axes[col]\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùå No filter results to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Method Chaining Demo\n",
    "\n",
    "Demonstrate the fluent interface with method chaining:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Complex method chaining example\nchained_result = (\n    kitten.generate(width=800, height=600, image_id=1)  # Now 1-based indexing\n    .smart_crop(width=600, height=400, save_steps=False)\n    .apply_filter(\"sepia\")\n    .save(get_output_path(\"notebook_chained.jpg\"))\n)\n\nprint(f\"‚úÖ Method chaining completed: {chained_result}\")\ndisplay(Image(chained_result))\n\n# Show the power of chaining\nprint(\"\\nüîó This single chain performed:\")\nprint(\"   1. Generated 800x600 image from kitten #1\")\nprint(\"   2. Smart cropped to 600x400 with computer vision\")\nprint(\"   3. Applied sepia filter\")\nprint(\"   4. Saved the final result\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Processing Demo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Batch processing configuration\nbatch_configs = [\n    {\"width\": 400, \"height\": 300, \"filter_type\": \"grayscale\", \"image_id\": 1},  # Now 1-based\n    {\"width\": 500, \"height\": 281, \"filter_type\": \"sepia\", \"image_id\": 2},\n    {\"width\": 600, \"height\": 400, \"filter_type\": \"blur\", \"image_id\": 3},\n]\n\n# Process batch in output folder\nbatch_results = kitten.batch_process(batch_configs, str(output_folder / \"batch_output\"))\n\nprint(f\"‚úÖ Batch processing completed: {len(batch_results)} images\")\nfor i, result in enumerate(batch_results):\n    print(f\"   {i+1}. {result}\")\n\n# Display batch results\nif batch_results:\n    fig, axes = plt.subplots(1, len(batch_results), figsize=(15, 5))\n    fig.suptitle('Batch Processing Results', fontsize=16)\n    \n    if len(batch_results) == 1:\n        axes = [axes]\n    \n    for i, result_path in enumerate(batch_results):\n        if os.path.exists(result_path):\n            img = mpimg.imread(result_path)\n            axes[i].imshow(img)\n            config = batch_configs[i]\n            title = f\"{config['width']}x{config['height']}\\n{config['filter_type']}\"\n            axes[i].set_title(title, fontsize=10)\n            axes[i].axis('off')\n    \n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance and Crop Information"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import time\n\n# Performance test\nstart_time = time.time()\n\n# Generate and process an image\nprocessor = kitten.generate(width=1200, height=800, image_id=1)  # Now 1-based indexing\nsmart_processor = processor.smart_crop(width=1920, height=1080, save_steps=False)\nresult = smart_processor.save(get_output_path(\"notebook_performance_test.jpg\"))\n\nend_time = time.time()\nprocessing_time = end_time - start_time\n\nprint(f\"‚è±Ô∏è  Processing time: {processing_time:.2f} seconds\")\nprint(f\"üìä Generated 1920x1080 image with smart cropping\")\n\n# Show crop information if available\nif hasattr(smart_processor, 'crop_info'):\n    crop_info = smart_processor.crop_info\n    print(f\"\\nüîç Crop Information:\")\n    print(f\"   Original size: {crop_info.get('original_size', 'N/A')}\")\n    print(f\"   Target size: {crop_info.get('target_size', 'N/A')}\")\n    print(f\"   Crop box: {crop_info.get('crop_box', 'N/A')}\")\n    print(f\"   Subject bbox: {crop_info.get('subject_bbox', 'N/A')}\")\n    print(f\"   Contour area: {crop_info.get('contour_area', 'N/A')}\")\n\n# Display final performance test result\nif os.path.exists(result):\n    display(Image(result))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "üéâ **PlaceKitten Phase 2 Complete!**\n",
    "\n",
    "‚úÖ **Computer Vision Pipeline**: Edge detection, contour analysis, subject identification  \n",
    "‚úÖ **Smart Cropping Engine**: Rule-of-thirds, optimal positioning, boundary safety  \n",
    "‚úÖ **Step Visualization**: 9-step debug output with processing stages  \n",
    "‚úÖ **Filter Pipeline**: Multiple filters with method chaining  \n",
    "‚úÖ **Batch Processing**: Multiple image processing workflows  \n",
    "‚úÖ **Performance**: Fast processing with detailed crop information  \n",
    "\n",
    "The PlaceKitten library is ready for Phase 3 (Advanced Features) and Phase 4 (MCP Integration)!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Cleanup generated files (optional)\nimport glob\n\n# List all generated files in output folder\ngenerated_files = list(output_folder.glob(\"notebook_*\")) + list(output_folder.glob(\"*batch_output*\"))\nprint(f\"üìÅ Generated {len(generated_files)} files during this demo:\")\nfor f in sorted(generated_files):\n    print(f\"   üìÑ {f.name}\")\n\nprint(f\"\\nüìÅ All files saved in: {output_folder.absolute()}\")\n\n# Uncomment to clean up:\n# for f in generated_files:\n#     try:\n#         f.unlink()\n#         print(f\"üóëÔ∏è  Removed {f.name}\")\n#     except:\n#         pass"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}