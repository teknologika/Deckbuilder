{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PlaceKitten Demo Notebook ğŸ±\n",
    "\n",
    "Interactive demonstration of PlaceKitten's Phase 2 features:\n",
    "- Computer Vision Pipeline\n",
    "- Smart Cropping Engine\n",
    "- Step Visualization System\n",
    "- Filter Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ Cleaning up previous run images...\n",
      "   ğŸ—‘ï¸  Removed random_none_1751028685.jpg\n",
      "   ğŸ—‘ï¸  Removed notebook_pixelate.jpg\n",
      "   ğŸ—‘ï¸  Removed notebook_chained_1751028686.jpg\n",
      "   ğŸ—‘ï¸  Removed notebook_full_size_1751028685.jpg\n",
      "   ğŸ—‘ï¸  Removed notebook_random_1751028685.jpg\n",
      "   ğŸ—‘ï¸  Removed aspect_original_1751028685.jpg\n",
      "   ğŸ—‘ï¸  Removed notebook_blur.jpg\n",
      "   ğŸ—‘ï¸  Removed notebook_width_only_1751028685.jpg\n",
      "   ğŸ—‘ï¸  Removed notebook_sepia.jpg\n",
      "   ğŸ—‘ï¸  Removed random_valid_1751028685.jpg\n",
      "   ğŸ—‘ï¸  Removed notebook_original.jpg\n",
      "   ğŸ—‘ï¸  Removed full_size_medium.jpg\n",
      "   ğŸ—‘ï¸  Removed aspect_height_scaled_1751028685.jpg\n",
      "   ğŸ—‘ï¸  Removed full_size_large.jpg\n",
      "   ğŸ—‘ï¸  Removed notebook_height_only_1751028685.jpg\n",
      "   ğŸ—‘ï¸  Removed full_size_small.jpg\n",
      "   ğŸ—‘ï¸  Removed random_forced_1751028685.jpg\n",
      "   ğŸ—‘ï¸  Removed notebook_grayscale.jpg\n",
      "   ğŸ—‘ï¸  Removed notebook_invert.jpg\n",
      "   ğŸ—‘ï¸  Removed directory batch_output\n",
      "   ğŸ—‘ï¸  Removed random_invalid_1751028685.jpg\n",
      "   ğŸ—‘ï¸  Removed notebook_performance_test.jpg\n",
      "   ğŸ—‘ï¸  Removed aspect_width_scaled_1751028685.jpg\n",
      "âœ… Cleanup complete!\n",
      "âœ… PlaceKitten imported successfully!\n",
      "ğŸ“ Project root: /Users/bruce/GitHub/teknologika/Deckbuilder\n",
      "ğŸ“ Module path: /Users/bruce/GitHub/teknologika/Deckbuilder/src\n",
      "ğŸ“ PlaceKitten images: /Users/bruce/GitHub/teknologika/Deckbuilder/src/placekitten/images/\n",
      "ğŸ“ Output folder: /Users/bruce/GitHub/teknologika/Deckbuilder/tests/placekitten/notebook_output\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import Image, display\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "# Get the notebook's directory and navigate to project root\n",
    "notebook_dir = Path(__file__).parent if '__file__' in globals() else Path.cwd()\n",
    "# Since we're in tests/placekitten/, go up 2 levels to reach project root\n",
    "project_root = notebook_dir.parent.parent\n",
    "src_path = project_root / \"src\"\n",
    "\n",
    "# Add src to Python path for module imports\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Create output folder for notebook images\n",
    "output_folder = Path(\"notebook_output\")\n",
    "\n",
    "# Clean up any existing images from previous runs\n",
    "if output_folder.exists():\n",
    "    print(\"ğŸ§¹ Cleaning up previous run images...\")\n",
    "    for item in output_folder.iterdir():\n",
    "        if item.is_file():\n",
    "            item.unlink()\n",
    "            print(f\"   ğŸ—‘ï¸  Removed {item.name}\")\n",
    "        elif item.is_dir():\n",
    "            shutil.rmtree(item)\n",
    "            print(f\"   ğŸ—‘ï¸  Removed directory {item.name}\")\n",
    "    print(\"âœ… Cleanup complete!\")\n",
    "else:\n",
    "    print(\"ğŸ“ Creating fresh output folder...\")\n",
    "\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# Import PlaceKitten (images are self-contained in src/placekitten/images/)\n",
    "from placekitten import PlaceKitten, list_available_filters\n",
    "\n",
    "print(\"âœ… PlaceKitten imported successfully!\")\n",
    "print(f\"ğŸ“ Project root: {project_root}\")\n",
    "print(f\"ğŸ“ Module path: {src_path}\")\n",
    "print(f\"ğŸ“ PlaceKitten images: {src_path}/placekitten/images/\")\n",
    "print(f\"ğŸ“ Output folder: {output_folder.absolute()}\")\n",
    "\n",
    "# Helper function to get output path\n",
    "def get_output_path(filename):\n",
    "    return str(output_folder / filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic PlaceKitten Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ± Found 6 kitten images:\n",
      "  1: ACuteKitten-1.png\n",
      "  2: ACuteKitten-2.png\n",
      "  3: ACuteKitten-3.png\n",
      "  4: TwoKitttens Playing-1.png\n",
      "  5: TwoKitttens Playing-2.png\n",
      "  6: TwoKitttensSleeping-1.png\n",
      "\n",
      "ğŸ¨ Available filters: grayscale, greyscale, blur, sepia, invert, brightness, contrast, saturation, sharpness, pixelate, edge_detection, emboss, smooth\n"
     ]
    }
   ],
   "source": [
    "# Initialize PlaceKitten\n",
    "kitten = PlaceKitten(\"demo\")\n",
    "\n",
    "# Show available images\n",
    "images = kitten.list_available_images()\n",
    "count = kitten.get_image_count()\n",
    "\n",
    "print(f\"ğŸ± Found {count} kitten images:\")\n",
    "for i, img in enumerate(images, 1):  # Show with 1-based indexing\n",
    "    print(f\"  {i}: {img}\")\n",
    "\n",
    "# Show available filters\n",
    "filters = list_available_filters()\n",
    "print(f\"\\nğŸ¨ Available filters: {', '.join(filters)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. New Flexible Features Demo\n",
    "\n",
    "PlaceKitten now supports:\n",
    "- **Optional dimensions**: Specify width only, height only, both, or neither\n",
    "- **Aspect ratio preservation**: When one dimension is given, the other is calculated\n",
    "- **Smart random selection**: Invalid or missing image_id automatically uses random\n",
    "- **1-based indexing**: More intuitive numbering (1=first image, not 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Full size image: (1024, 1536)\n",
      "âœ… Width only (200px): (200, 300)\n",
      "âœ… Height only (200px): (133, 200)\n",
      "âœ… Random image: (500, 300)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; flex-direction: column; gap: 30px;\">\n",
       "    <div>\n",
       "        <h4>Full Size - Actual Dimensions: (1024, 1536)</h4>\n",
       "        <img src=\"notebook_output/notebook_full_size_1751028780.jpg?v=1751028780\" style=\"border: 2px solid #ccc;\">\n",
       "    </div>\n",
       "    <div>\n",
       "        <h4>Width Only (200px) - Actual Dimensions: (200, 300)</h4>\n",
       "        <img src=\"notebook_output/notebook_width_only_1751028780.jpg?v=1751028780\" style=\"border: 2px solid #00f;\">\n",
       "    </div>\n",
       "    <div>\n",
       "        <h4>Height Only (200px) - Actual Dimensions: (133, 200)</h4>\n",
       "        <img src=\"notebook_output/notebook_height_only_1751028780.jpg?v=1751028780\" style=\"border: 2px solid #f00;\">\n",
       "    </div>\n",
       "    <div>\n",
       "        <h4>Random Image - Actual Dimensions: (500, 300)</h4>\n",
       "        <img src=\"notebook_output/notebook_random_1751028780.jpg?v=1751028780\" style=\"border: 2px solid #0f0;\">\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate images using new flexible features\n",
    "import time\n",
    "\n",
    "# Test dimensions - adjust these to see different scaling results\n",
    "test_width = 200   # Width for width-only scaling test\n",
    "test_height = 200  # Height for height-only scaling test\n",
    "\n",
    "# Add timestamp for cache busting\n",
    "timestamp = int(time.time())\n",
    "\n",
    "# 1. Full size image (no dimensions specified)\n",
    "full_size = kitten.generate(image_id=1)\n",
    "full_output = full_size.save(get_output_path(f\"notebook_full_size_{timestamp}.jpg\"))\n",
    "print(f\"âœ… Full size image: {full_size.get_size()}\")\n",
    "\n",
    "# 2. Width only - height calculated from aspect ratio\n",
    "width_only = kitten.generate(width=test_width, image_id=1)  # 1-based indexing\n",
    "width_output = width_only.save(get_output_path(f\"notebook_width_only_{timestamp}.jpg\"))\n",
    "print(f\"âœ… Width only ({test_width}px): {width_only.get_size()}\")\n",
    "\n",
    "# 3. Height only - width calculated from aspect ratio  \n",
    "height_only = kitten.generate(height=test_height, image_id=1)  # Same image\n",
    "height_output = height_only.save(get_output_path(f\"notebook_height_only_{timestamp}.jpg\"))\n",
    "print(f\"âœ… Height only ({test_height}px): {height_only.get_size()}\")\n",
    "\n",
    "# 4. Random image selection (no image_id)\n",
    "random_img = kitten.generate(width=500, height=300)\n",
    "random_output = random_img.save(get_output_path(f\"notebook_random_{timestamp}.jpg\"))\n",
    "print(f\"âœ… Random image: {random_img.get_size()}\")\n",
    "\n",
    "# Display examples at ACTUAL SIZES to demonstrate scaling\n",
    "from IPython.display import HTML\n",
    "display(HTML(f\"\"\"\n",
    "<div style=\"display: flex; flex-direction: column; gap: 30px;\">\n",
    "    <div>\n",
    "        <h4>Full Size - Actual Dimensions: {full_size.get_size()}</h4>\n",
    "        <img src=\"{full_output}?v={timestamp}\" style=\"border: 2px solid #ccc;\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <h4>Width Only ({test_width}px) - Actual Dimensions: {width_only.get_size()}</h4>\n",
    "        <img src=\"{width_output}?v={timestamp}\" style=\"border: 2px solid #00f;\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <h4>Height Only ({test_height}px) - Actual Dimensions: {height_only.get_size()}</h4>\n",
    "        <img src=\"{height_output}?v={timestamp}\" style=\"border: 2px solid #f00;\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <h4>Random Image - Actual Dimensions: {random_img.get_size()}</h4>\n",
    "        <img src=\"{random_output}?v={timestamp}\" style=\"border: 2px solid #0f0;\">\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Aspect Ratio Preservation Demo\n",
    "\n",
    "Demonstrate how PlaceKitten preserves aspect ratios when scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Original image: 1024x1536\n",
      "ğŸ“ Original aspect ratio: 0.667\n",
      "ğŸ“ Scaled by width (800px): 800x1200\n",
      "ğŸ“ New aspect ratio: 0.667\n",
      "ğŸ“ Scaled by height (600px): 400x600\n",
      "ğŸ“ New aspect ratio: 0.667\n",
      "âœ… Aspect ratios perfectly preserved!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; flex-direction: column; gap: 30px; align-items: flex-start;\">\n",
       "    <div style=\"text-align: left;\">\n",
       "        <h4>Original - 1024x1536 (Ratio: 0.667)</h4>\n",
       "        <img src=\"notebook_output/aspect_original_1751028780.jpg?v=1751028780\" style=\"border: 2px solid #ccc;\">\n",
       "    </div>\n",
       "    <div style=\"text-align: left;\">\n",
       "        <h4>Width Scaled to 800px - 800x1200 (Ratio: 0.667)</h4>\n",
       "        <img src=\"notebook_output/aspect_width_scaled_1751028780.jpg?v=1751028780\" style=\"border: 2px solid #00f;\">\n",
       "    </div>\n",
       "    <div style=\"text-align: left;\">\n",
       "        <h4>Height Scaled to 600px - 400x600 (Ratio: 0.667)</h4>\n",
       "        <img src=\"notebook_output/aspect_height_scaled_1751028780.jpg?v=1751028780\" style=\"border: 2px solid #f00;\">\n",
       "    </div>\n",
       "</div>\n",
       "<p><strong>Notice:</strong> All three images show the same kitten but at different scales, demonstrating perfect aspect ratio preservation.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test aspect ratio preservation with same image\n",
    "import time\n",
    "test_image_id = 1  # Use first image for consistency\n",
    "\n",
    "# Test dimensions for aspect ratio demonstration\n",
    "demo_width = 800   # Width for width-scaling demo\n",
    "demo_height = 600  # Height for height-scaling demo\n",
    "\n",
    "# Add timestamp for cache busting\n",
    "timestamp = int(time.time())\n",
    "\n",
    "# Get original dimensions\n",
    "original = kitten.generate(image_id=test_image_id)\n",
    "orig_w, orig_h = original.get_size()\n",
    "orig_ratio = orig_w / orig_h\n",
    "\n",
    "print(f\"ğŸ“ Original image: {orig_w}x{orig_h}\")\n",
    "print(f\"ğŸ“ Original aspect ratio: {orig_ratio:.3f}\")\n",
    "\n",
    "# Scale by width only\n",
    "scaled_by_width = kitten.generate(width=demo_width, image_id=test_image_id)\n",
    "scale_w_size = scaled_by_width.get_size()\n",
    "scale_w_ratio = scale_w_size[0] / scale_w_size[1]\n",
    "\n",
    "print(f\"ğŸ“ Scaled by width ({demo_width}px): {scale_w_size[0]}x{scale_w_size[1]}\")\n",
    "print(f\"ğŸ“ New aspect ratio: {scale_w_ratio:.3f}\")\n",
    "\n",
    "# Scale by height only\n",
    "scaled_by_height = kitten.generate(height=demo_height, image_id=test_image_id)\n",
    "scale_h_size = scaled_by_height.get_size()\n",
    "scale_h_ratio = scale_h_size[0] / scale_h_size[1]\n",
    "\n",
    "print(f\"ğŸ“ Scaled by height ({demo_height}px): {scale_h_size[0]}x{scale_h_size[1]}\")\n",
    "print(f\"ğŸ“ New aspect ratio: {scale_h_ratio:.3f}\")\n",
    "\n",
    "# Check preservation\n",
    "ratio_diff_w = abs(orig_ratio - scale_w_ratio)\n",
    "ratio_diff_h = abs(orig_ratio - scale_h_ratio)\n",
    "\n",
    "if ratio_diff_w < 0.01 and ratio_diff_h < 0.01:\n",
    "    print(\"âœ… Aspect ratios perfectly preserved!\")\n",
    "else:\n",
    "    print(f\"âŒ Aspect ratio drift: {ratio_diff_w:.4f}, {ratio_diff_h:.4f}\")\n",
    "\n",
    "# Save examples\n",
    "orig_output = original.save(get_output_path(f\"aspect_original_{timestamp}.jpg\"))\n",
    "width_output = scaled_by_width.save(get_output_path(f\"aspect_width_scaled_{timestamp}.jpg\"))\n",
    "height_output = scaled_by_height.save(get_output_path(f\"aspect_height_scaled_{timestamp}.jpg\"))\n",
    "\n",
    "# Visual comparison at ACTUAL SIZES to show scaling differences\n",
    "from IPython.display import HTML\n",
    "display(HTML(f\"\"\"\n",
    "<div style=\"display: flex; flex-direction: column; gap: 30px; align-items: flex-start;\">\n",
    "    <div style=\"text-align: left;\">\n",
    "        <h4>Original - {orig_w}x{orig_h} (Ratio: {orig_ratio:.3f})</h4>\n",
    "        <img src=\"{orig_output}?v={timestamp}\" style=\"border: 2px solid #ccc;\">\n",
    "    </div>\n",
    "    <div style=\"text-align: left;\">\n",
    "        <h4>Width Scaled to {demo_width}px - {scale_w_size[0]}x{scale_w_size[1]} (Ratio: {scale_w_ratio:.3f})</h4>\n",
    "        <img src=\"{width_output}?v={timestamp}\" style=\"border: 2px solid #00f;\">\n",
    "    </div>\n",
    "    <div style=\"text-align: left;\">\n",
    "        <h4>Height Scaled to {demo_height}px - {scale_h_size[0]}x{scale_h_size[1]} (Ratio: {scale_h_ratio:.3f})</h4>\n",
    "        <img src=\"{height_output}?v={timestamp}\" style=\"border: 2px solid #f00;\">\n",
    "    </div>\n",
    "</div>\n",
    "<p><strong>Notice:</strong> All three images show the same kitten but at different scales, demonstrating perfect aspect ratio preservation.</p>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Smart Random Selection Demo\n",
    "\n",
    "Test how PlaceKitten handles invalid/missing image IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ² Testing smart random selection...\n",
      "âœ… Valid ID (1): (300, 200)\n",
      "âœ… Invalid ID (999) â†’ random fallback: (300, 200)\n",
      "âœ… No ID â†’ random: (300, 200)\n",
      "âœ… Forced random (overrides ID): (300, 200)\n",
      "\n",
      "ğŸ‰ No errors! Invalid IDs gracefully fall back to random selection.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; flex-direction: column; gap: 20px;\">\n",
       "    <div>\n",
       "        <h4>Valid ID (1) - 300x200</h4>\n",
       "        <img src=\"notebook_output/random_valid_1751028780.jpg?v=1751028780\" style=\"border: 2px solid #0f0;\">\n",
       "    </div>\n",
       "    <div>\n",
       "        <h4>Invalid ID (999) â†’ Random Fallback - 300x200</h4>\n",
       "        <img src=\"notebook_output/random_invalid_1751028780.jpg?v=1751028780\" style=\"border: 2px solid #f80;\">\n",
       "    </div>\n",
       "    <div>\n",
       "        <h4>No ID â†’ Random Selection - 300x200</h4>\n",
       "        <img src=\"notebook_output/random_none_1751028780.jpg?v=1751028780\" style=\"border: 2px solid #80f;\">\n",
       "    </div>\n",
       "    <div>\n",
       "        <h4>Forced Random (overrides ID) - 300x200</h4>\n",
       "        <img src=\"notebook_output/random_forced_1751028780.jpg?v=1751028780\" style=\"border: 2px solid #f08;\">\n",
       "    </div>\n",
       "</div>\n",
       "<p><strong>Notice:</strong> All images are exactly 300x200 pixels, showing consistent size handling with random selection.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test smart random selection\n",
    "import time\n",
    "print(\"ğŸ² Testing smart random selection...\")\n",
    "\n",
    "# Add timestamp for cache busting\n",
    "timestamp = int(time.time())\n",
    "\n",
    "# Generated width\n",
    "image_width=150\n",
    "\n",
    "# Valid image ID (should work normally)\n",
    "valid_img = kitten.generate(width=image_width image_id=1)\n",
    "valid_output = valid_img.save(get_output_path(f\"random_valid_{timestamp}.jpg\"))\n",
    "print(f\"âœ… Valid ID (1): {valid_img.get_size()}\")\n",
    "\n",
    "# Invalid image ID (should fall back to random - no error!)\n",
    "try:\n",
    "    invalid_img = kitten.generate(width=image_width image_id=999)\n",
    "    invalid_output = invalid_img.save(get_output_path(f\"random_invalid_{timestamp}.jpg\"))\n",
    "    print(f\"âœ… Invalid ID (999) â†’ random fallback: {invalid_img.get_size()}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Should not error: {e}\")\n",
    "\n",
    "# No image ID (should use random)\n",
    "no_id_img = kitten.generate(width=image_width)\n",
    "no_id_output = no_id_img.save(get_output_path(f\"random_none_{timestamp}.jpg\"))\n",
    "print(f\"âœ… No ID â†’ random: {no_id_img.get_size()}\")\n",
    "\n",
    "# Force random selection\n",
    "force_random = kitten.generate(width=image_width, image_id=1, random_selection=True)\n",
    "force_output = force_random.save(get_output_path(f\"random_forced_{timestamp}.jpg\"))\n",
    "print(f\"âœ… Forced random (overrides ID): {force_random.get_size()}\")\n",
    "\n",
    "print(\"\\nğŸ‰ No errors! Invalid IDs gracefully fall back to random selection.\")\n",
    "\n",
    "# Display random examples at actual size (all 300x200)\n",
    "from IPython.display import HTML\n",
    "display(HTML(f\"\"\"\n",
    "<div style=\"display: flex; flex-direction: column; gap: 20px;\">\n",
    "    <div>\n",
    "        <h4>Valid ID (1)</h4>\n",
    "        <img src=\"{valid_output}?v={timestamp}\" style=\"border: 2px solid #0f0;\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <h4>Invalid ID (999) â†’ Random Fallback</h4>\n",
    "        <img src=\"{invalid_output}?v={timestamp}\" style=\"border: 2px solid #f80;\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <h4>No ID â†’ Random Selection</h4>\n",
    "        <img src=\"{no_id_output}?v={timestamp}\" style=\"border: 2px solid #80f;\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <h4>Forced Random (overrides ID)</h4>\n",
    "        <img src=\"{force_output}?v={timestamp}\" style=\"border: 2px solid #f08;\">\n",
    "    </div>\n",
    "</div>\n",
    "<p><strong>Notice:</strong> All images are exactly {image_width}, showing consistent size handling with random selection.</p>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Smart Cropping with Computer Vision\n",
    "\n",
    "This demonstrates the 9-step intelligent cropping process:\n",
    "1. Original analysis\n",
    "2. Grayscale conversion\n",
    "3. Noise reduction (Gaussian blur)\n",
    "4. Edge detection (Canny algorithm)\n",
    "5. Contour analysis\n",
    "6. Subject bounding box\n",
    "7. Rule of thirds grid\n",
    "8. Optimal crop area\n",
    "9. Final result"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test smart cropping with computer vision pipeline\nimport time\n\n# Add timestamp for cache busting\ntimestamp = int(time.time())\n\nprint(\"ğŸ”¬ Testing 9-step smart cropping computer vision pipeline...\")\n\n# Generate a base image for smart cropping\nbase_image = kitten.generate(width=800, height=600, image_id=2)  # Use image #2\nprint(f\"âœ… Base image generated: {base_image.get_size()}\")\n\n# Test smart cropping with step visualization\nprint(\"\\nğŸ¯ Smart cropping with step-by-step visualization:\")\nsmart_cropped = base_image.smart_crop(\n    width=600, \n    height=400, \n    save_steps=True,  # Enable step visualization\n    output_folder=get_output_path(\"smart_crop_steps\")\n)\n\n# Save the final smart cropped result\nfinal_output = smart_cropped.save(get_output_path(f\"smart_crop_final_{timestamp}.jpg\"))\nprint(f\"âœ… Smart cropping completed: {smart_cropped.get_size()}\")\n\n# Get the step files for display\nfrom pathlib import Path\nsteps_folder = Path(get_output_path(\"smart_crop_steps\"))\nif steps_folder.exists():\n    step_files = sorted([f for f in steps_folder.iterdir() if f.suffix.lower() == '.jpg'])\n    print(f\"ğŸ“Š Generated {len(step_files)} visualization steps\")\n    \n    # Display all 9 steps plus final result\n    from IPython.display import HTML\n    \n    # Create HTML for step-by-step visualization\n    steps_html = []\n    step_names = [\n        \"1-original\", \"2-grayscale\", \"3-blurred\", \"4-edges\", \"5-largest-contour\",\n        \"6-bounding-box\", \"7-rule-of-thirds\", \"8-crop-area\", \"9-final\"\n    ]\n    \n    for i, step_file in enumerate(step_files):\n        step_name = step_names[i] if i < len(step_names) else f\"step-{i+1}\"\n        steps_html.append(f\"\"\"\n        <div style=\"text-align: center; margin: 15px;\">\n            <h4>Step {i+1}: {step_name.split('-', 1)[1].replace('-', ' ').title()}</h4>\n            <img src=\"{step_file}?v={timestamp}\" style=\"border: 2px solid #333;\">\n        </div>\n        \"\"\")\n    \n    # Add final result\n    steps_html.append(f\"\"\"\n    <div style=\"text-align: center; margin: 15px;\">\n        <h4>Final Smart Cropped Result: 600x400</h4>\n        <img src=\"{final_output}?v={timestamp}\" style=\"border: 3px solid #0f0;\">\n    </div>\n    \"\"\")\n    \n    display(HTML(f\"\"\"\n    <div style=\"display: flex; flex-direction: column; gap: 20px;\">\n        <h3>ğŸ”¬ Complete Computer Vision Pipeline</h3>\n        {''.join(steps_html)}\n    </div>\n    \"\"\"))\n    \nelse:\n    print(\"âŒ Step visualization folder not found\")\n    # Just display the final result\n    from IPython.display import HTML\n    display(HTML(f\"\"\"\n    <div style=\"margin: 20px 0;\">\n        <h4>Smart Cropped Result - 600x400</h4>\n        <img src=\"{final_output}?v={timestamp}\" style=\"border: 2px solid #0f0;\">\n    </div>\n    \"\"\"))\n\nprint(\"\\nğŸ§  Computer Vision Analysis:\")\nprint(\"   1. âœ… Original analysis - Input image processed\")\nprint(\"   2. âœ… Grayscale conversion - Color removed for edge detection\")\nprint(\"   3. âœ… Noise reduction - Gaussian blur applied\")\nprint(\"   4. âœ… Edge detection - Canny algorithm finds boundaries\")\nprint(\"   5. âœ… Contour analysis - Shape detection and filtering\")\nprint(\"   6. âœ… Subject bounding box - Main subject identified\")\nprint(\"   7. âœ… Rule of thirds grid - Composition guidelines applied\")\nprint(\"   8. âœ… Optimal crop area - Best crop region calculated\")\nprint(\"   9. âœ… Final result - Smart cropped image generated\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Display step files if available\nif steps_folder.exists() and step_files:\n    fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n    fig.suptitle('PlaceKitten Smart Cropping: 9-Step Computer Vision Pipeline', fontsize=16)\n    \n    # Step names for matplotlib display\n    step_titles = [\n        \"1. Original Analysis\", \"2. Grayscale Conversion\", \"3. Noise Reduction\",\n        \"4. Edge Detection\", \"5. Contour Analysis\", \"6. Subject Bounding Box\",\n        \"7. Rule of Thirds\", \"8. Crop Area\", \"9. Final Result\"\n    ]\n    \n    for i, step_file in enumerate(step_files[:9]):  # Show first 9 steps\n        row = i // 3\n        col = i % 3\n        \n        if step_file.exists():\n            img = mpimg.imread(str(step_file))\n            axes[row, col].imshow(img)\n            axes[row, col].set_title(step_titles[i], fontsize=10)\n            axes[row, col].axis('off')\n        else:\n            axes[row, col].axis('off')\n    \n    # Hide any empty subplots\n    for i in range(len(step_files), 9):\n        row = i // 3\n        col = i % 3\n        axes[row, col].axis('off')\n    \n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"ğŸ“Š Using matplotlib fallback display...\")\n    \n    # Simple before/after comparison if steps aren't available\n    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n    fig.suptitle('Smart Cropping: Before and After', fontsize=16)\n    \n    # Show original image\n    original_path = base_image.save(get_output_path(f\"original_for_crop_{timestamp}.jpg\"))\n    if Path(original_path).exists():\n        orig_img = mpimg.imread(original_path)\n        axes[0].imshow(orig_img)\n        axes[0].set_title('Original (800x600)', fontsize=12)\n        axes[0].axis('off')\n    \n    # Show final result\n    if Path(final_output).exists():\n        final_img = mpimg.imread(final_output)\n        axes[1].imshow(final_img)\n        axes[1].set_title('Smart Cropped (600x400)', fontsize=12)\n        axes[1].axis('off')\n    \n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Filter Pipeline Demo\n\nTest the various image filters available in PlaceKitten:",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test all available filters\nimport time\n\n# Add timestamp for cache busting\ntimestamp = int(time.time())\n\nfilters_to_test = ['grayscale', 'sepia', 'blur', 'invert', 'pixelate']\nfilter_results = {}\n\nbase_processor = kitten.generate(width=400, height=300, image_id=3)  # Use image #3\n\n# Generate original\noriginal_file = base_processor.save(get_output_path(f\"filter_original_{timestamp}.jpg\"))\nfilter_results['original'] = original_file\n\n# Apply each filter\nfor filter_name in filters_to_test:\n    try:\n        filtered_processor = base_processor.apply_filter(filter_name)\n        output_file = filtered_processor.save(get_output_path(f\"filter_{filter_name}_{timestamp}.jpg\"))\n        filter_results[filter_name] = output_file\n        print(f\"âœ… {filter_name} filter applied\")\n    except Exception as e:\n        print(f\"âŒ {filter_name} filter failed: {e}\")\n        filter_results[filter_name] = None\n\nprint(f\"\\nğŸ“Š Generated {len([f for f in filter_results.values() if f])} filter variations\")\n\n# Display filter results with HTML - KEEP THIS HTML OUTPUT!\nfrom IPython.display import HTML\nfilter_html = []\n\nfor filter_name, file_path in filter_results.items():\n    if file_path and Path(file_path).exists():\n        filter_html.append(f\"\"\"\n        <div style=\"text-align: center; margin: 15px;\">\n            <h4>{filter_name.title()} Filter</h4>\n            <img src=\"{file_path}?v={timestamp}\" style=\"border: 2px solid #666;\">\n        </div>\n        \"\"\")\n\ndisplay(HTML(f\"\"\"\n<div style=\"display: flex; flex-wrap: wrap; gap: 20px; justify-content: center;\">\n    <h3>ğŸ¨ Filter Pipeline Results</h3>\n    <div style=\"display: flex; flex-wrap: wrap; gap: 20px; justify-content: center;\">\n        {''.join(filter_html)}\n    </div>\n</div>\n\"\"\"))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Display filter results in a matplotlib grid\navailable_filters = [(k, v) for k, v in filter_results.items() if v and Path(v).exists()]\nn_filters = len(available_filters)\n\nif n_filters > 0:\n    cols = 3\n    rows = (n_filters + cols - 1) // cols\n    \n    fig, axes = plt.subplots(rows, cols, figsize=(12, 4 * rows))\n    fig.suptitle('PlaceKitten Filter Pipeline Results', fontsize=16)\n    \n    # Handle single row case\n    if rows == 1:\n        axes = [axes] if cols == 1 else axes\n    \n    for i, (filter_name, filepath) in enumerate(available_filters):\n        row = i // cols\n        col = i % cols\n        \n        ax = axes[row][col] if rows > 1 else axes[col]\n        \n        img = mpimg.imread(filepath)\n        ax.imshow(img)\n        ax.set_title(filter_name.title(), fontsize=12)\n        ax.axis('off')\n    \n    # Hide empty subplots\n    for i in range(n_filters, rows * cols):\n        row = i // cols\n        col = i % cols\n        ax = axes[row][col] if rows > 1 else axes[col]\n        ax.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"âŒ No filter results to display\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "## 7. Method Chaining Demo\n\nDemonstrate the fluent interface with method chaining:"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance and Crop Information"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "## 8. Batch Processing Demo"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "ğŸ‰ **PlaceKitten Enhanced Features Complete!**\n",
    "\n",
    "### âœ… **New Flexible Features**:\n",
    "- **Optional dimensions**: width only, height only, both, or neither\n",
    "- **Aspect ratio preservation**: Automatic scaling calculations\n",
    "- **Smart random selection**: Graceful fallback for invalid image IDs\n",
    "- **1-based indexing**: Intuitive numbering (1=first image)\n",
    "\n",
    "### âœ… **Existing Advanced Features**:\n",
    "- **Computer Vision Pipeline**: Edge detection, contour analysis, subject identification  \n",
    "- **Smart Cropping Engine**: Rule-of-thirds, optimal positioning, boundary safety  \n",
    "- **Step Visualization**: 9-step debug output with processing stages  \n",
    "- **Filter Pipeline**: Multiple filters with method chaining  \n",
    "- **Batch Processing**: Multiple image processing workflows  \n",
    "- **Performance**: Fast processing with detailed crop information  \n",
    "\n",
    "### ğŸ”„ **Full Backward Compatibility**:\n",
    "All existing code continues to work unchanged. The library is now more flexible while maintaining all original functionality.\n",
    "\n",
    "The PlaceKitten library is ready for Phase 3 (Advanced Features) and Phase 4 (MCP Integration)!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "## 9. Performance and Crop Information"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 11. Summary\n\nğŸ‰ **PlaceKitten Enhanced Features Complete!**\n\n### âœ… **New Flexible Features**:\n- **Optional dimensions**: width only, height only, both, or neither\n- **Aspect ratio preservation**: Automatic scaling calculations\n- **Smart random selection**: Graceful fallback for invalid image IDs\n- **1-based indexing**: Intuitive numbering (1=first image)\n\n### âœ… **Advanced Computer Vision Features**:\n- **9-Step Smart Cropping Pipeline**: Edge detection, contour analysis, subject identification  \n- **Rule-of-thirds Optimization**: Intelligent composition-based cropping\n- **Step Visualization**: Complete debug output showing all processing stages  \n- **Subject Detection**: Automated identification of main image subjects\n\n### âœ… **Additional Features**:\n- **Filter Pipeline**: Multiple image filters with method chaining  \n- **Batch Processing**: Multiple image processing workflows  \n- **Performance Optimization**: Fast processing with detailed crop information  \n- **Cache-busting Display**: Reliable notebook visualization\n\n### ğŸ”„ **Full Backward Compatibility**:\nAll existing code continues to work unchanged. The library is now more flexible while maintaining all original functionality.\n\n### ğŸ“ **Image Display Note**:\nGenerated images are always created at exact requested dimensions. No CSS constraints applied - images show at actual pixel dimensions.\n\nThe PlaceKitten library is ready for Phase 3 (Advanced Features) and Phase 4 (MCP Integration)!",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Cleanup generated files (optional) - with HTML display of results\nimport glob\n\n# List all generated files in output folder\ngenerated_files = list(output_folder.glob(\"notebook_*\")) + list(output_folder.glob(\"*batch_output*\"))\nprint(f\"ğŸ“ Generated {len(generated_files)} files during this demo:\")\nfor f in sorted(generated_files):\n    print(f\"   ğŸ“„ {f.name}\")\n\nprint(f\"\\nğŸ“ All files saved in: {output_folder.absolute()}\")\n\n# Show a summary grid of some key generated images with HTML\nfrom IPython.display import HTML\nsummary_images = []\n\n# Look for key demo images to display\nkey_files = [\n    'notebook_full_size', 'notebook_width_only', 'notebook_height_only', \n    'aspect_original', 'aspect_width_scaled', 'aspect_height_scaled',\n    'smart_crop_final', 'filter_original', 'filter_sepia', 'filter_grayscale'\n]\n\nfor key in key_files:\n    matching_files = [f for f in generated_files if key in f.name]\n    if matching_files:\n        file_path = matching_files[0]  # Take the most recent\n        summary_images.append(f\"\"\"\n        <div style=\"text-align: center; margin: 10px;\">\n            <h5>{key.replace('_', ' ').title()}</h5>\n            <img src=\"{file_path}\" style=\"border: 1px solid #999; max-width: 150px;\">\n        </div>\n        \"\"\")\n\nif summary_images:\n    display(HTML(f\"\"\"\n    <div style=\"margin: 20px 0;\">\n        <h3>ğŸ“¸ Demo Results Summary</h3>\n        <div style=\"display: flex; flex-wrap: wrap; gap: 15px; justify-content: center;\">\n            {''.join(summary_images)}\n        </div>\n    </div>\n    \"\"\"))\n\n# Uncomment to clean up:\n# for f in generated_files:\n#     try:\n#         f.unlink()\n#         print(f\"ğŸ—‘ï¸  Removed {f.name}\")\n#     except:\n#         pass"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}